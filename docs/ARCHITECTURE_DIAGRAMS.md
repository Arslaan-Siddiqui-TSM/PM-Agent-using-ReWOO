# ğŸ¨ System Architecture Diagrams

This reflects the current FastAPI-based API, Reflection planning workflow (draft â†’ critique â†’ revise), UnifiedLLM (OpenAI/Gemini/NVIDIA), and async document processing with session management.

## API Endpoints Overview

```
Health & Info:
  GET  /                         # API info and version
  GET  /health/                  # Health check
  GET  /docs                     # Swagger UI

Document Upload & Processing:
  POST /api/upload               # Upload PDFs or use defaults (creates session)
  GET  /api/upload-status/{id}   # Poll async processing status

Feasibility & Planning:
  POST /api/feasibility          # Generate feasibility assessment
  POST /api/generate-plan        # Generate project implementation plan

Utilities:
  GET  /api/document-types       # List supported document types
  GET  /api/sessions/{id}        # Get session info
  DELETE /api/sessions/{id}      # Delete session and files
  GET  /api/file-content         # Read generated files (outputs/ only)
```

## High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CLIENT (Web UI or direct API)               â”‚
â”‚   â€¢ React/Vite frontend (http://localhost:5173)             â”‚
â”‚   â€¢ FastAPI at /api, health at /health                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FASTAPI APPLICATION (server.py)             â”‚
â”‚  â€¢ /api/upload â†’ creates session, parses docs (async)       â”‚
â”‚  â€¢ /api/upload-status/{session_id} â†’ check processing       â”‚
â”‚  â€¢ /api/feasibility â†’ generate feasibility report           â”‚
â”‚  â€¢ /api/generate-plan â†’ Reflection (draftâ†’critiqueâ†’revise)  â”‚
â”‚  â€¢ /api/file-content â†’ read outputs/feasibility/plan files  â”‚
â”‚  â€¢ /api/sessions/{id} â†’ get/delete session info             â”‚
â”‚  â€¢ /api/document-types â†’ supported document types           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DOCUMENT INTELLIGENCE PIPELINE                   â”‚
â”‚  â€¢ IntelligentDocumentParser (Docling-first; chunking)      â”‚
â”‚  â€¢ Classify â†’ Extract â†’ Analyze (cache-aware)               â”‚
â”‚  â€¢ Generates Planning Context (structured, compact)         â”‚
â”‚  â€¢ Async background processing with status tracking         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             REFLECTION PLANNING AGENT (LangGraph)           â”‚
â”‚  â€¢ Iterates: draft â†’ critique â†’ revise                      â”‚
â”‚  â€¢ Uses Planning Context (+ feasibility, if available)      â”‚
â”‚  â€¢ UnifiedLLM: OpenAI, Gemini, or NVIDIA (env-controlled)   â”‚
â”‚  â€¢ Automatic fallback: OpenAI â†’ Gemini â†’ NVIDIA             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROJECT IMPLEMENTATION PLAN               â”‚
â”‚  â€¢ Markdown saved to outputs/                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Interaction (API-centric)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI (server.py)                        â”‚
â”‚  - routes: /api/*, /health/*               â”‚
â”‚  - 3 routers: agent, utils, health         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Route Handlers (delegation pattern)        â”‚
â”‚  - UploadHandler (async processing)        â”‚
â”‚  - FeasibilityHandler                      â”‚
â”‚  - PlanGenerationHandler                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DocumentIntelligencePipeline                â”‚
â”‚  - Classifier / Extractor / Analyzer        â”‚
â”‚  - IntelligentDocumentParser (Docling)      â”‚
â”‚  - Parsing cache (data/parsing_cache)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DoclingParser (PDF â†’ MD)      â”‚   â”‚ UnifiedLLM (provider)   â”‚
â”‚  - Parsing cache (SHA256)     â”‚   â”‚  - OpenAI (gpt-4o-mini) â”‚
â”‚  - Output: MD + JSON files    â”‚   â”‚  - Gemini (gemini-2.5)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  - NVIDIA (qwen3-next)  â”‚
                â”‚                   â”‚  - Auto fallback supportâ”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
                     Reflection Graph (LangGraph)
                     draft â†’ critique â†’ revise
```

## Data Flow

```
PDFs (data/files or uploaded) â†’ DoclingParser
         â”‚
         â–¼
Markdown Files (.md) + JSON Files (.json)
         â”‚  (async background processing)
         â–¼
Feasibility Assessment â†’ Feasibility Graph (LangGraph)
         â”‚  - Stage 1: Thinking Summary
         â”‚  - Stage 2: Feasibility Report
         â–¼
Project Plan â†’ Reflection Graph (LangGraph)
         â”‚  - Draft â†’ Critique â†’ Revise (iterative)
         â–¼
Final Plan â†’ outputs/*.md
```

## Caching Strategy

```
1) Document Processing Cache (data/parsing_cache/)
   - SHA256-based file hashing
   - Stores parsed markdown + JSON metadata
   - Avoids re-parsing identical PDFs

2) Document Intelligence Cache (data/embedding_cache/)
   - Classification results cache
   - Extraction results cache
   - Analysis results cache
```

## Runtime Components & Ports

```
Frontend  : http://localhost:5173 (Vite dev server)
Backend   : http://localhost:8000 (FastAPI)

LLM Providers (configurable via LLM_PROVIDER env var):
  - OpenAI (default)
  - Google Gemini
  - NVIDIA NIM
  - Automatic fallback chain
```

## Decision Tree (Document Classification)

```
PDF â†’ sample pages â†’ LLM classify
   â”œâ”€ confidence â‰¥ 0.8 â†’ type-specific extraction
   â”œâ”€ 0.5 â‰¤ conf < 0.8 â†’ keep type + add generic fallback
   â””â”€ conf < 0.5       â†’ "unknown" + generic extraction
          â”‚
          â””â†’ cache classification by file hash
```

## Async Processing Flow

```
1. Upload Request (POST /api/upload)
   â”œâ”€ Create session
   â”œâ”€ Copy/validate files
   â”œâ”€ Set status = "processing"
   â””â”€ Start background thread

2. Background Processing
   â”œâ”€ Parse PDFs â†’ Markdown (Docling)
   â”œâ”€ Convert MD â†’ JSON (Document Intelligence)
   â”œâ”€ Update session.parsed_documents
   â””â”€ Set status = "completed" or "failed"

3. Client Polling (GET /api/upload-status/{session_id})
   â”œâ”€ Returns: status, message, parsed_documents count
   â””â”€ Frontend polls until status != "processing"

4. Feasibility/Plan Generation
   â”œâ”€ Validates status == "completed"
   â”œâ”€ Returns 425 (Too Early) if still processing
   â””â”€ Proceeds only when all processing done
```

## Analysis Report Generation

```
Inputs: classifications + extractions for all docs
   â”œâ”€ Gap analysis
   â”œâ”€ Conflict detection
   â”œâ”€ Cross-document references
   â””â”€ Coverage / readiness scoring
â†’ Export JSON + Markdown under outputs/intermediate/
```

## LLM Provider Architecture

```
UnifiedLLM (src/config/llm_config.py)
   â”‚
   â”œâ”€ Primary Provider Selection (env: LLM_PROVIDER)
   â”‚  â”œâ”€ nvidia â†’ NVIDIA NIM (qwen3-next-80b-a3b-instruct)
   â”‚  â”œâ”€ openai â†’ OpenAI (gpt-4o-mini, default)
   â”‚  â””â”€ gemini â†’ Google Gemini (gemini-2.5-pro)
   â”‚
   â”œâ”€ Automatic Fallback Chain
   â”‚  â””â”€ If primary fails â†’ try: OpenAI â†’ Gemini â†’ NVIDIA
   â”‚
   â”œâ”€ Features
   â”‚  â”œâ”€ Pure LangChain (init_chat_model)
   â”‚  â”œâ”€ Runtime provider switching
   â”‚  â”œâ”€ Token usage tracking with Rich UI
   â”‚  â””â”€ Session-level statistics
   â”‚
   â””â”€ Configuration
      â”œâ”€ LLM_PROVIDER (nvidia/openai/gemini)
      â”œâ”€ NVIDIA_MODEL, OPENAI_MODEL, GEMINI_MODEL
      â””â”€ NVIDIA_API_KEY, OPENAI_API_KEY, GOOGLE_API_KEY
```

## Example Walkthrough (condensed)

```
Input: requirements.pdf, tech-spec.pdf
â†’ Upload: POST /api/upload (creates session, starts async processing)
â†’ Poll: GET /api/upload-status/{session_id} (until status=completed)
â†’ Parse: PDF â†’ Markdown + JSON (cached where possible)
â†’ Feasibility: POST /api/feasibility (saves two files: thinking + report)
â†’ Plan: POST /api/generate-plan (saves project_plan_*.md)
â†’ View: GET /api/file-content?file_path=outputs/...
```

## State Management (Reflection)

The planning flow uses two state graphs with LangGraph:

**FeasibilityState** (feasibility_graph.py):

- md_file_paths: list of parsed markdown documents
- session_id: current session identifier
- development_context: optional user-provided context
- thinking_summary: stage 1 output (comprehensive analysis)
- feasibility_report: stage 2 output (final assessment)
- unified_context_path: path to unified context file

**ReflectionState** (graph.py):

- task: description of the planning goal
- document_context: structured context from the pipeline
- max_iterations: number of reflection cycles
- iterations: collected iteration artifacts (draft, critique, revise)
- final_plan: captured from the `revise` node
- current_draft: latest draft version
- current_critique: latest critique

Sessions are in-memory (`src/core/session_storage.py`) with these properties:

- session_id, created_at, expiry tracking
- document_paths, parsed_documents, parsed_documents_dir
- processing_status: pending/processing/completed/failed
- status_message, processing_error
- feasibility paths and pipeline results

## File Structure (relevant parts)

```
rewoo-demonstration/
â”œâ”€ server.py                     # FastAPI entrypoint
â”œâ”€ docker-compose.yml            # Qdrant service (optional)
â”œâ”€ src/
â”‚  â”œâ”€ routes/                    # /api endpoints
â”‚  â”‚  â”œâ”€ planning_agent.py       # Main API routes (upload, feasibility, plan)
â”‚  â”‚  â”œâ”€ upload_handler.py       # Upload logic with async processing
â”‚  â”‚  â”œâ”€ feasibility_handler.py  # Feasibility generation logic
â”‚  â”‚  â”œâ”€ plan_generation_handler.py  # Plan generation logic
â”‚  â”‚  â”œâ”€ utils_endpoints.py      # Utility endpoints (sessions, file-content)
â”‚  â”‚  â””â”€ health_check.py         # Health check endpoint
â”‚  â”œâ”€ core/                      # pipeline, session, cache
â”‚  â”‚  â”œâ”€ session.py              # Session class
â”‚  â”‚  â”œâ”€ session_storage.py      # In-memory session storage
â”‚  â”‚  â””â”€ document_analyzer.py    # Document analysis pipeline
â”‚  â”œâ”€ agents/                    # classifier, extractor, etc.
â”‚  â”œâ”€ config/                    # llm_config, feature flags
â”‚  â”‚  â””â”€ llm_config.py           # UnifiedLLM with multi-provider support
â”‚  â”œâ”€ states/                    # State classes
â”‚  â”‚  â”œâ”€ reflection_state.py     # ReflectionState
â”‚  â”‚  â””â”€ feasibility_state.py    # FeasibilityState
â”‚  â””â”€ app/                       # LangGraph implementations
â”‚     â”œâ”€ graph.py                # Reflection graph (draftâ†’reflectâ†’revise)
â”‚     â”œâ”€ feasibility_graph.py    # Feasibility graph
â”‚     â”œâ”€ feasibility_agent.py    # Feasibility generation logic
â”‚     â”œâ”€ draft.py                # Draft generation node
â”‚     â”œâ”€ reflect.py              # Reflection/critique node
â”‚     â””â”€ revise.py               # Revision node
â”œâ”€ data/
â”‚  â”œâ”€ files/                     # sample PDFs
â”‚  â”œâ”€ uploads/                   # user uploads (runtime)
â”‚  â”œâ”€ parsing_cache/             # parsing metadata cache
â”‚  â””â”€ embedding_cache/           # document intelligence cache
â”œâ”€ output/                       # feasibility + plan markdown
â”‚  â””â”€ intermediate/              # intermediate outputs
â”œâ”€ outputs/                      # alternative output location
â”œâ”€ frontend/                     # React app (Vite)
â””â”€ docs/                         # this file + other docs
```
