# ğŸ¨ System Architecture Diagrams

This reflects the current FastAPI-based API, Reflection planning workflow (draft â†’ critique â†’ revise), UnifiedLLM (OpenAI/Gemini), and Qdrant-backed RAG with an embedding cache.

## High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CLIENT (Web UI or direct API)               â”‚
â”‚   â€¢ React/Vite frontend (http://localhost:5173)             â”‚
â”‚   â€¢ FastAPI at /api, health at /health                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FASTAPI APPLICATION (server.py)             â”‚
â”‚  â€¢ /api/upload â†’ creates session, parses docs, RAG ingest   â”‚
â”‚  â€¢ /api/generate-embeddings â†’ manual RAG (re)processing     â”‚
â”‚  â€¢ /api/feasibility â†’ generate feasibility report           â”‚
â”‚  â€¢ /api/generate-plan â†’ Reflection (draftâ†’critiqueâ†’revise)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DOCUMENT INTELLIGENCE PIPELINE                   â”‚
â”‚  â€¢ IntelligentDocumentParser (Docling-first; chunking)      â”‚
â”‚  â€¢ Classify â†’ Extract â†’ Analyze (cache-aware)               â”‚
â”‚  â€¢ Generates Planning Context (structured, compact)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG / VECTOR STORE                      â”‚
â”‚  â€¢ OpenAI embeddings (text-embedding-3-*)                   â”‚
â”‚  â€¢ Qdrant (Docker) for vector storage                       â”‚
â”‚  â€¢ EmbeddingCacheManager (copy cached points)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             REFLECTION PLANNING AGENT (LangGraph)           â”‚
â”‚  â€¢ Iterates: draft â†’ critique â†’ revise                      â”‚
â”‚  â€¢ Uses Planning Context (+ feasibility, if available)      â”‚
â”‚  â€¢ UnifiedLLM: OpenAI o4-mini or Gemini (env-controlled)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROJECT IMPLEMENTATION PLAN               â”‚
â”‚  â€¢ Markdown saved to outputs/                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Interaction (API-centric)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI (server.py)                        â”‚
â”‚  - routes: /api/*, /health/*               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DocumentIntelligencePipeline                â”‚
â”‚  - Classifier / Extractor / Analyzer        â”‚
â”‚  - IntelligentDocumentParser (Docling)      â”‚
â”‚  - EmbeddingCacheManager (data/embedding_cache)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QdrantManager (vector store)  â”‚   â”‚ UnifiedLLM (provider)   â”‚
â”‚  - Qdrant (6333/6334)         â”‚   â”‚  - OpenAI (o4-mini)     â”‚
â”‚  - Collection: pm_agent_<id>  â”‚   â”‚  - Gemini (gemini-2.5)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                            â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
                     Reflection Graph (LangGraph)
                     draft â†’ critique â†’ revise
```

## Data Flow (including RAG path)

```
PDFs (data/files or uploaded) â†’ IntelligentDocumentParser
     â”œâ”€ Pre-chunked (Docling HybridChunker) if available
     â””â”€ Fallback: RecursiveCharacterTextSplitter
         â”‚
         â–¼
Embeddings (OpenAI) â†’ Qdrant (session collection)
         â”‚
         â–¼
Classification â†’ Extraction â†’ Analysis (cached)
         â”‚
         â–¼
Planning Context (structured text) â†’ Reflection Agent
         â”‚
         â–¼
Feasibility (optional) + Final Plan â†’ outputs/*.md
```

## Caching Strategy

```
1) Pipeline cache (cache/)
   - classifications/{hash}.json
   - extractions/{hash}.json
   - analysis/{set_hash}.json

2) Embedding cache (data/embedding_cache/)
   - Stores metadata per file hash:
     â€¢ parsed_md_path
     â€¢ qdrant_collection (usually pm_agent_cache)
     â€¢ qdrant_point_ids (reused via copy)
     â€¢ sessions_used_in [...]

3) Session collection in Qdrant
   - Name: pm_agent_<session_id[:8]>
   - New parses are embedded and added
   - Cached points copied into session collection for reuse
```

## Runtime Components & Ports

```
Frontend  : http://localhost:5173 (Vite dev server)
Backend   : http://localhost:8000 (FastAPI)
Qdrant    : http://localhost:6333 (REST), 6334 (gRPC)
```

## Decision Tree (Document Classification)

```
PDF â†’ sample pages â†’ LLM classify
   â”œâ”€ confidence â‰¥ 0.8 â†’ type-specific extraction
   â”œâ”€ 0.5 â‰¤ conf < 0.8 â†’ keep type + add generic fallback
   â””â”€ conf < 0.5       â†’ "unknown" + generic extraction
          â”‚
          â””â†’ cache classification by file hash
```

## Analysis Report Generation

```
Inputs: classifications + extractions for all docs
   â”œâ”€ Gap analysis
   â”œâ”€ Conflict detection
   â”œâ”€ Cross-document references
   â””â”€ Coverage / readiness scoring
â†’ Export JSON + Markdown under outputs/intermediate/
```

## Example Walkthrough (condensed)

```
Input: requirements.pdf, tech-spec.pdf
â†’ Pipeline: classify/extract/analyze (cached where possible)
â†’ RAG: embed + store in Qdrant; copy cached points if available
â†’ Feasibility: /api/feasibility saves two markdown files
â†’ Plan: /api/generate-plan saves project_plan_*.md
```

## State Management (Reflection)

The planning flow uses a `ReflectionState` passed through the LangGraph:

- task: description of the planning goal
- document_context: structured context from the pipeline
- max_iterations: number of reflection cycles
- iterations: collected iteration artifacts
- final_plan: captured from the `revise` node

Sessions are in-memory (`src/core/session_storage.py`); uploaded file paths, pipeline results, feasibility paths, and Qdrant info are stored per session id.

## File Structure (relevant parts)

```
rewoo-demonstration/
â”œâ”€ server.py                     # FastAPI entrypoint
â”œâ”€ docker-compose.yml            # Qdrant service
â”œâ”€ src/
â”‚  â”œâ”€ routes/                    # /api endpoints
â”‚  â”œâ”€ core/                      # pipeline, qdrant, cache
â”‚  â”œâ”€ agents/                    # classifier, extractor, etc.
â”‚  â”œâ”€ config/                    # llm_config, feature flags
â”‚  â”œâ”€ states/                    # ReflectionState
â”‚  â””â”€ app/                       # reflection graph
â”œâ”€ data/
â”‚  â”œâ”€ files/                     # sample PDFs
â”‚  â”œâ”€ uploads/                   # user uploads (runtime)
â”‚  â”œâ”€ parsed_documents/          # parser outputs
â”‚  â””â”€ embedding_cache/           # embedding metadata cache
â”œâ”€ outputs/                      # feasibility + plan markdown
â”œâ”€ frontend/                     # React app (Vite)
â””â”€ docs/                         # this file + other docs
```
