# ğŸ” Complete Codebase Analysis

## ğŸ¯ What This System Does

**PM-Agent** is an **AI-Powered Project Management Planning System** that automatically generates comprehensive, executive-ready project plans from multiple project documents (PDFs).

### Core Capabilities:
1. **Intelligent Document Processing** - Classifies, extracts, and analyzes project documents (BRDs, specs, test plans, etc.)
2. **Feasibility Assessment** - Generates feasibility reports with risk analysis
3. **Automated Project Planning** - Creates detailed project plans using an iterative AI reflection pattern
4. **Vector Search (RAG)** - Semantic search over documents using Qdrant vector database
5. **Multi-Format Support** - Handles PDFs, DOCX, images, spreadsheets, etc.
6. **Web Interface** - React frontend for easy interaction

---

## ğŸ“ Folder Structure & Roles

### ğŸ”· **`src/`** - All Application Source Code

The heart of the application. Contains 8 subdirectories:

#### **`src/agents/`** - Document Processing Agents
Specialized AI agents for document processing tasks.

| File | Purpose |
|------|---------|
| **`document_classifier.py`** | LLM-based agent that classifies PDFs into types (BRD, Tech Spec, Test Plan, etc.) based on content analysis |
| **`content_extractor.py`** | Type-aware extraction agent that pulls structured information (requirements, features, tech details) from classified documents |
| **`diagram_generator.py`** | Agent for generating project diagrams and visualizations |
| **`docling_processor.py`** | Universal document processor supporting multiple formats (PDF, DOCX, XLSX, images) with OCR capabilities |

**Role**: Transform raw documents into structured, queryable data.

---

#### **`src/app/`** - Core Application Logic (Reflection Pattern)
Implements the iterative **Draft â†’ Critique â†’ Revise** workflow.

| File | Purpose |
|------|---------|
| **`graph.py`** | LangGraph workflow orchestration - defines the state machine for the reflection pattern |
| **`draft.py`** | Generates project plan drafts using LLM based on document context and revision instructions |
| **`reflect.py`** | Acts as a "red-team reviewer" - critiques the draft, identifies gaps, conflicts, and issues |
| **`revise.py`** | Decision node - decides whether to accept the plan or request revisions with specific instructions |
| **`feasibility_agent.py`** | Generates feasibility assessments and questions from uploaded documents |

**Role**: The "brain" of project plan generation using iterative improvement.

---

#### **`src/config/`** - Configuration Modules
Centralized configuration management.

| File | Purpose |
|------|---------|
| **`llm_config.py`** | LLM provider configuration (OpenAI/Gemini), model selection, temperature settings, unified API wrapper |
| **`document_intelligence_config.py`** | Pipeline configuration for document processing (classification, extraction, analysis settings) |
| **`feature_flags.py`** | Feature toggles for enabling/disabling functionality (Qdrant, caching, Docling, etc.) |

**Role**: Centralized settings for easy configuration without code changes.

---

#### **`src/core/`** - Core Business Logic
The foundation layer handling document intelligence, caching, and data management.

| File | Purpose |
|------|---------|
| **`document_intelligence_pipeline.py`** | **Main orchestrator** - coordinates classification â†’ extraction â†’ analysis â†’ RAG processing |
| **`document_analyzer.py`** | Cross-document analysis - finds gaps, conflicts, missing info, generates confidence scores |
| **`intelligent_document_parser.py`** | Smart PDF routing - uses PyMuPDF for simple docs, Docling for complex ones, saves as Markdown |
| **`cache_manager.py`** | Caches classification/extraction results to avoid re-processing (file-hash based) |
| **`embedding_cache_manager.py`** | **Global embedding cache** - prevents re-embedding same documents across sessions (SHA256 hash based) |
| **`qdrant_manager.py`** | Vector database management - creates embeddings, stores in Qdrant, handles semantic search |
| **`session.py`** | Session data model - stores user session state (documents, assessments, results) |
| **`session_storage.py`** | In-memory session store (dictionary-based, 60-minute timeout) |

**Role**: Heavy lifting for document processing, vector search, and state management.

---

#### **`src/routes/`** - FastAPI Route Handlers
REST API endpoints for the backend service.

| File | Purpose |
|------|---------|
| **`planning_agent.py`** | **Main API endpoints**: `/upload`, `/feasibility`, `/generate-plan`, `/generate-embeddings` |
| **`utils_endpoints.py`** | Utility endpoints for document types, file listing, session management |
| **`health_check.py`** | Simple health check endpoint (`/health`) |

**Role**: HTTP interface for client applications to interact with the system.

---

#### **`src/states/`** - State Definitions
Pydantic models defining application state structures.

| File | Purpose |
|------|---------|
| **`reflection_state.py`** | State for the reflection workflow (iterations, drafts, critiques, decisions) |
| **`rewoo_state.py`** | Legacy ReWOO pattern state (plan-execute-solve paradigm) - not actively used |

**Role**: Type-safe state containers for workflow management.

---

#### **`src/tools/`** - External Tool Integrations
Wrappers for external services.

| File | Purpose |
|------|---------|
| **`search_tool.py`** | Tavily search API wrapper for web searches (currently not heavily used) |

**Role**: Integration layer for third-party services.

---

#### **`src/utils/`** - Helper Utilities
Common utility functions used across the application.

| File | Purpose |
|------|---------|
| **`constants.py`** | Application constants (upload directory: `data/uploads/`) |
| **`helper.py`** | Common helpers: logging, file loading, prompt loading, document reading |

**Role**: Shared utilities to avoid code duplication.

---

### ğŸ”· **`docs/`** - All Documentation

Comprehensive documentation organized by category.

#### **`docs/setup/`** - Installation & Setup Guides
- `START_HERE.md` - New user onboarding guide
- `QUICK_START.md` - Fast setup for experienced users
- `DOCKER_SETUP.md` - Docker and Qdrant configuration

#### **`docs/implementation/`** - Technical Details
- `IMPLEMENTATION_SUMMARY.md` - Feature implementation overview
- `QDRANT_MIGRATION_COMPLETE.md` - Vector database architecture
- `CHANGES.md` - Changelog

#### **`docs/guides/`** - User Guides
- `ENV_CONFIGURATION.md` - Environment variables reference
- `ERROR_FIXES.md` - Troubleshooting guide
- `ERRORS_AND_SOLUTIONS.md` - Common errors and fixes
- `IMPLEMENTATION_STATUS.md` - Feature status matrix

#### **Root Level Documentation**
- `PROJECT_STRUCTURE.md` - This file's companion - complete structure
- `MIGRATION_GUIDE.md` - Migration instructions for new structure
- `CODEBASE_ANALYSIS.md` - This file

**Role**: Knowledge base for users and developers.

---

### ğŸ”· **`scripts/`** - Utility & Setup Scripts

Organized helper scripts for various tasks.

#### **`scripts/setup/`** - Setup Scripts
- `init_qdrant.py` - Initialize Qdrant vector database, verify setup
- `populate_qdrant.py` - Pre-populate Qdrant with sample data
- `fix_errors.py` - Automated error detection and fixing

#### **`scripts/testing/`** - Test Scripts
- `test_document_intelligence.py` - Test the document intelligence pipeline
- `test_qdrant_migration.py` - Test Qdrant integration
- `test_docling_qdrant.py` - Test Docling + Qdrant workflow

#### **Root Level Scripts**
- `generate_feasibility_questions.py` - Generate feasibility assessment from PDFs
- `generate_project_plan.py` - Generate project plan (CLI version)

**Role**: Standalone utilities for setup, testing, and manual operations.

---

### ğŸ”· **`data/`** - All Data Files (Git-Ignored)

Consolidated data storage directory.

| Subdirectory | Contents |
|--------------|----------|
| **`files/`** | Input PDF documents (BRDs, specs, test plans, etc.) |
| **`uploads/`** | User-uploaded files via API |
| **`parsed_documents/`** | Parsed markdown files organized by session |
| **`embedding_cache/`** | Global embedding cache (prevents re-embedding same docs) |
| **`qdrant_storage/`** | Qdrant vector database storage (Docker volume) |
| **`vector_store/`** | Additional vector store data |
| **`logs/`** | Application logs |

**Role**: Persistent data storage isolated from code.

---

### ğŸ”· **`tests/`** - Test Files

Unit and integration tests.

- `test_api.py` - API endpoint integration tests

**Role**: Quality assurance and regression prevention.

---

### ğŸ”· **`prompts/`** - LLM Prompt Templates

Carefully crafted prompts for AI interactions.

| File | Purpose |
|------|---------|
| **`reflect_prompt.txt`** | Red-team review prompt - critique drafts for gaps and issues |
| **`revise_prompt.txt`** | Decision prompt - accept or request revisions |
| **`feasibility_promptv2.txt`** | Generate feasibility assessments |
| **`feasprompt_enhanced.txt`** | Enhanced feasibility generation |
| **Legacy prompts** | `planner_prompt.txt`, `solver_prompt.txt` (ReWOO pattern - not actively used) |

**Role**: Prompt engineering for consistent, high-quality AI outputs.

---

### ğŸ”· **`frontend/`** - React Web Application

Modern React + Vite frontend for user interaction.

| Location | Purpose |
|----------|---------|
| **`src/App.jsx`** | Main React component with 5-step workflow UI |
| **`src/App.css`** | Application styles |
| **`vite.config.js`** | Vite build configuration |
| **`package.json`** | NPM dependencies |

**Steps in UI:**
1. Upload Documents
2. Answer Development Process Questions
3. Review Feasibility Assessment
4. Provide Feedback (optional)
5. View Final Project Plan

**Role**: User-friendly interface for the system.

---

### ğŸ”· **Root Level Files**

| File | Purpose |
|------|---------|
| **`server.py`** | FastAPI application entry point - starts the web server |
| **`docker-compose.yml`** | Docker services configuration (Qdrant vector DB) |
| **`pyproject.toml`** | Python project metadata and dependencies |
| **`requirements.txt`** | Frozen Python dependencies for pip |
| **`.env`** | Environment variables (API keys, not in git) |
| **`.gitignore`** | Git ignore patterns |
| **`README.md`** | Main project documentation |

---

## ğŸ”„ Complete System Workflow

### **Overview: From Documents to Project Plan**

```
ğŸ“„ Upload PDFs
    â†“
ğŸ§  Document Intelligence Pipeline
    â†“
ğŸ’¾ Vector Embeddings (Qdrant)
    â†“
ğŸ“‹ Feasibility Assessment
    â†“
ğŸ” Iterative Plan Generation (Draft â†’ Critique â†’ Revise)
    â†“
âœ… Final Executive-Ready Project Plan
```

---

## ğŸ“‹ Detailed Workflow Breakdown

### **Phase 1: Document Upload & Processing**

**Step 1.1: Upload Documents (API: `/api/upload`)**

```
Frontend â†’ API â†’ Session Creation
                    â†“
               Store files in data/uploads/
                    â†“
               Trigger Document Intelligence Pipeline
```

**What happens:**
- User uploads PDFs or uses default files from `data/files/`
- System creates a session with unique ID
- Files are stored and associated with session

---

**Step 1.2: Document Intelligence Pipeline**

```
PDFs â†’ Intelligent Parser â†’ Classification â†’ Extraction â†’ Analysis â†’ Embeddings â†’ Qdrant
```

**Detailed Flow:**

1. **Intelligent Parsing** (`intelligent_document_parser.py`)
   - Detects document complexity (images, tables, etc.)
   - **Simple PDFs** â†’ PyMuPDF (fast, 2-5 seconds)
   - **Complex PDFs** â†’ Docling (comprehensive, 10-30 seconds)
   - Saves as Markdown in `data/parsed_documents/session_xxx/`

2. **Classification** (`document_classifier.py`)
   - LLM analyzes content (not just filename)
   - Classifies into types:
     - Business Requirements Document (BRD)
     - Technical Specification
     - Test Plan
     - Use Cases
     - Non-Functional Requirements
     - Other
   - Caches results (file-hash based)

3. **Content Extraction** (`content_extractor.py`)
   - Type-aware extraction based on classification
   - Extracts structured data:
     - Title, summary
     - Requirements (with priority)
     - Features (with descriptions)
     - Technical details (architecture, tech stack)
     - Dependencies, risks, constraints
   - Caches results

4. **Cross-Document Analysis** (`document_analyzer.py`)
   - Identifies gaps (missing document types)
   - Finds conflicts (contradictions between docs)
   - Generates confidence scores
   - Creates consolidated risks/dependencies/constraints
   - Outputs coverage score and planning readiness

5. **Embedding Generation** (`embedding_cache_manager.py` + `qdrant_manager.py`)
   - Checks global cache (SHA256 hash)
   - **Cache HIT**: Copies existing embeddings (90% faster, $0 cost)
   - **Cache MISS**: 
     - Splits markdown into chunks (1000 chars, 200 overlap)
     - Creates embeddings (OpenAI text-embedding-3-large)
     - Stores in Qdrant collection `pm_agent_sessionID`
     - Adds to global cache
   - Enables semantic search over documents

**Output:**
- `pipeline_result` stored in session:
  - Classifications
  - Extractions
  - Analysis report
  - Qdrant manager instance
  - Cache statistics

---

### **Phase 2: Feasibility Assessment**

**API Endpoint: `/api/feasibility`**

```
Session Context â†’ LLM (Feasibility Prompt) â†’ Assessment Report
```

**Process:**

1. **Retrieve Context**
   - Uses pipeline results (structured context) OR raw PDF text
   - Optionally includes development process information from user

2. **Development Context Integration**
   - User provides:
     - Methodology (Agile, Waterfall, etc.)
     - Team size
     - Timeline
     - Budget
     - Tech stack preferences
     - Constraints/risks
   - Saved to JSON for reference

3. **LLM Generation**
   - Uses `feasibility_promptv2.txt` or `feasprompt_enhanced.txt`
   - LLM analyzes documents and context
   - Generates two outputs:
     - **Thinking Summary**: Internal reasoning, considerations
     - **Feasibility Report**: Structured assessment with:
       - Project viability score
       - Key risks and mitigations
       - Resource requirements
       - Timeline feasibility
       - Technical feasibility
       - Recommendations

4. **Output Files**
   - `data/outputs/thinking_summary_[sessionID]_[timestamp].md`
   - `data/outputs/feasibility_report_[sessionID]_[timestamp].md`
   - Both stored in session for plan generation

---

### **Phase 3: Project Plan Generation (Reflection Pattern)**

**API Endpoint: `/api/generate-plan`**

This is where the magic happens! Uses an iterative **Draft â†’ Critique â†’ Revise** loop.

```
Document Context + Feasibility
         â†“
    [DRAFT NODE]
         â†“
    Generate Plan Draft
         â†“
    [REFLECT NODE]
         â†“
    Critique Draft (Red-Team Review)
         â†“
    [REVISE NODE]
         â†“
    Decision: Accept or Request Revisions?
         â†“
    Accept? â†’ FINALIZE
    Revise? â†’ Loop back to DRAFT with specific instructions
```

---

#### **Detailed Reflection Loop:**

**Iteration 1:**

1. **DRAFT Node** (`draft.py`)
   - **Input**:
     - Task: "Create comprehensive project plan"
     - Document context (from pipeline)
     - Feasibility assessment
     - Revision instructions: None (initial draft)
   
   - **Process**:
     - Loads prompt from `prompts/draft_prompt.txt` (not in repo, generated at runtime)
     - Formats prompt with all context
     - LLM generates comprehensive project plan:
       - Project Overview
       - Scope and Objectives
       - Epics/Modules
       - Functional Requirements (User Stories)
       - Non-Functional Requirements
       - Dependencies & Constraints
       - Risks & Mitigations
       - Timeline & Milestones
       - Team Structure
       - Budget Estimate
       - Communication Plan
       - Success Metrics
   
   - **Output**: 
     - `current_draft` = generated plan
     - Stored in iteration history

2. **REFLECT Node** (`reflect.py`)
   - **Input**:
     - Current draft
     - Original task
     - Document context
     - Feasibility assessment
   
   - **Process**:
     - Uses `prompts/reflect_prompt.txt`
     - Acts as **red-team reviewer** / delivery director
     - Performs thorough review:
       - Verifies alignment with task and feasibility
       - Checks completeness of all sections
       - Validates consistency (scope â†” timeline â†” budget)
       - Identifies unclear ownership
       - Flags missing dependencies
       - Finds contradictions
       - Highlights gaps
   
   - **Output**: Critique in structured format:
     - Overall Verdict (Pass/Fail)
     - Strengths
     - Critical Issues (Blockers)
     - Improvement Checklist (actionable items)
     - Observations
   
3. **REVISE Node** (`revise.py`)
   - **Input**:
     - Current draft
     - Critique
     - Document context
     - Feasibility assessment
   
   - **Process**:
     - Uses `prompts/revise_prompt.txt`
     - Acts as **autonomous PM copilot**
     - Makes decision:
       - Reviews all critical issues
       - Validates alignment
       - Determines if draft is executive-ready
   
   - **Output**: JSON decision:
     ```json
     {
       "decision": "accept" | "revise",
       "rationale": "Brief explanation",
       "required_actions": "Specific, detailed revision instructions"
     }
     ```
   
   - **Routing**:
     - **"accept"** â†’ Go to FINALIZE node
     - **"revise"** â†’ Loop back to DRAFT node with `required_actions`

---

**Iteration 2+ (if revisions needed):**

1. **DRAFT Node** (again)
   - Now has `revision_instructions` from REVISE node
   - Example instructions:
     ```
     1. Add detailed budget breakdown (team costs, infrastructure, contingency)
     2. Clarify dependencies on Stripe API integration
     3. Add specific test coverage metrics (80% minimum)
     4. Include rollback procedure for deployment
     ```
   
   - LLM rewrites the ENTIRE plan addressing these issues
   - New draft replaces previous one

2. **REFLECT Node** (again)
   - Reviews new draft
   - Checks if previous issues are resolved
   - May find new issues or approve

3. **REVISE Node** (again)
   - Makes decision on new draft
   - Loop continues...

---

**Loop Termination:**

1. **Accepted by REVISE**: Plan is good â†’ FINALIZE
2. **Max iterations reached** (default: 5): Force accept best draft â†’ FINALIZE
3. **Error**: Exception handling â†’ Return partial result

---

**FINALIZE Node:**

- Sets `final_plan` to accepted draft
- Saves to file: `data/outputs/project_plan_[sessionID]_[timestamp].md`
- Returns to API endpoint

---

### **Phase 4: Frontend Display**

**React App Steps:**

1. **Upload** (Step 1)
   - User uploads PDFs or uses defaults
   - Shows upload progress and file list

2. **Development Questions** (Step 2)
   - User answers process questions (optional)
   - Methodology, team size, timeline, etc.

3. **Feasibility Review** (Step 3)
   - Shows generated feasibility report
   - Markdown rendering
   - User can review before continuing

4. **Feedback** (Step 4 - Optional)
   - User can provide additional context
   - Currently placeholder, not fully integrated

5. **Final Plan** (Step 5)
   - Shows complete project plan
   - Markdown rendering
   - Download option
   - Shows iteration count and execution time

---

## ğŸ”‘ Key Technologies & Patterns

### **1. Document Intelligence Pipeline**
- **Pattern**: Extract â†’ Transform â†’ Load (ETL)
- **Caching**: File-hash based (SHA256) for speed
- **Parsing**: Intelligent routing (PyMuPDF vs Docling)

### **2. Vector Search (RAG)**
- **Embeddings**: OpenAI text-embedding-3-large (3072 dimensions)
- **Vector DB**: Qdrant (Docker-hosted)
- **Chunking**: Recursive character splitter (1000/200)
- **Semantic Search**: Similarity search over document chunks

### **3. Reflection Pattern (Not ReWOO)**
- **Pattern**: Draft â†’ Critique â†’ Revise (iterative improvement)
- **Advantage**: Continuous refinement until quality threshold met
- **State**: LangGraph manages state transitions
- **Prompts**: Separate, specialized prompts for each role

### **4. Session Management**
- **Storage**: In-memory dictionary (production would use Redis)
- **Timeout**: 60 minutes
- **Isolation**: Each session has own Qdrant collection
- **State**: Full state preserved between API calls

### **5. Caching Strategy**
- **Level 1**: Classification/Extraction cache (file-hash)
- **Level 2**: Global embedding cache (SHA256)
- **Benefit**: 90% speed improvement, $0 re-embedding cost

---

## ğŸ’¾ Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND                            â”‚
â”‚  (React + Vite - Port 5173)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP REST API
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FASTAPI BACKEND                         â”‚
â”‚  (Python - Port 8000)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Routes: /upload, /feasibility, /generate-plan  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Document Intelligence Pipeline                  â”‚   â”‚
â”‚  â”‚  â€¢ Classification                                â”‚   â”‚
â”‚  â”‚  â€¢ Extraction                                    â”‚   â”‚
â”‚  â”‚  â€¢ Analysis                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Reflection Graph (LangGraph)                    â”‚   â”‚
â”‚  â”‚  â€¢ Draft Node                                    â”‚   â”‚
â”‚  â”‚  â€¢ Reflect Node                                  â”‚   â”‚
â”‚  â”‚  â€¢ Revise Node                                   â”‚   â”‚
â”‚  â”‚  â€¢ Finalize Node                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â†“                                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM PROVIDERS  â”‚              â”‚   QDRANT VECTOR DB   â”‚
â”‚  â€¢ OpenAI       â”‚              â”‚   (Docker - 6333)    â”‚
â”‚  â€¢ Gemini       â”‚              â”‚   â€¢ Embeddings       â”‚
â”‚  (via unified   â”‚              â”‚   â€¢ Semantic Search  â”‚
â”‚   wrapper)      â”‚              â”‚   â€¢ Cache Collection â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â†“
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚   FILE SYSTEM        â”‚
                                 â”‚   data/              â”‚
                                 â”‚   â€¢ files/           â”‚
                                 â”‚   â€¢ uploads/         â”‚
                                 â”‚   â€¢ parsed_docs/     â”‚
                                 â”‚   â€¢ cache/           â”‚
                                 â”‚   â€¢ outputs/         â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ System Execution Example

### **Real-World Scenario:**

**User uploads 3 PDFs:**
- Business Requirements Document.pdf
- Technical Specification.pdf
- Test Plan.pdf

---

**Timeline:**

**T+0s**: Upload files
- API creates session `abc123`
- Files stored in `data/uploads/`

**T+2s**: Start Document Intelligence Pipeline
- Parse 3 PDFs â†’ Markdown (PyMuPDF - all simple)
- Saved to `data/parsed_documents/session_abc123/raw/`

**T+5s**: Classification
- BRD â†’ "Business Requirements Document" (95% confidence)
- Tech Spec â†’ "Technical Specification" (98% confidence)
- Test Plan â†’ "Test Plan" (99% confidence)

**T+10s**: Extraction
- Extract 45 requirements, 12 features, tech stack details
- Structured JSON-like data created

**T+12s**: Analysis
- Coverage: 75% (missing Use Cases, NFR doc)
- 3 gaps identified
- 1 conflict found (timeline mismatch)
- Planning readiness: MEDIUM

**T+15s**: Embedding Generation
- Check cache: 2 docs cached (BRD, Tech Spec seen before)
- Cache HIT: Copy 38 chunks
- Cache MISS: Embed Test Plan â†’ 20 new chunks
- Total: 58 chunks in Qdrant collection `pm_agent_abc123`

**T+18s**: Pipeline complete
- Return to frontend: "Processed 3 files, 58 chunks, 2 cache hits"

---

**User answers development questions:**
- Methodology: Agile/Scrum
- Team: 5 developers
- Timeline: 6 months
- Budget: $500K

---

**T+25s**: Request feasibility assessment
- LLM analyzes all context (15K tokens)
- Generates thinking summary (internal reasoning)
- Generates feasibility report (8 sections, 2500 words)
- Saves both markdown files

**T+45s**: User reviews feasibility, clicks "Generate Plan"

---

**T+48s**: Start Reflection Loop

**Iteration 1:**

**T+50s**: DRAFT node
- LLM generates comprehensive 12-section plan (5000 words)
- Includes user stories, timeline, budget, risks

**T+75s**: REFLECT node
- Red-team review identifies issues:
  - Missing: Specific budget breakdown
  - Missing: Test coverage metrics
  - Gap: No rollback procedure
  - Conflict: Timeline vs resource allocation

**T+80s**: REVISE node
- Decision: REVISE
- Required actions: "Add detailed budget... Add test metrics... Include rollback..."

**Iteration 2:**

**T+82s**: DRAFT node (with revisions)
- LLM addresses all 4 issues
- New plan: 5500 words (more detailed)

**T+105s**: REFLECT node
- Review: Much better!
- Minor: Could improve communication plan
- No blockers

**T+110s**: REVISE node
- Decision: ACCEPT
- Rationale: "All critical issues resolved, executive-ready"

**T+112s**: FINALIZE
- Set `final_plan`
- Save to `data/outputs/project_plan_abc123_20251104_120000.md`

**T+113s**: Return to frontend
- Status: COMPLETED
- Iterations: 2
- Execution time: 88 seconds
- Display markdown plan

---

**Total time: ~2 minutes** for complete analysis and plan generation!

---

## ğŸ“Š System Metrics

### **Performance:**
- Simple PDF parsing: 2-5 seconds
- Complex PDF parsing: 10-30 seconds  
- Embedding generation (new doc): 1-2 seconds per chunk
- Embedding copy (cached): <0.1 seconds per chunk
- Draft generation: 20-30 seconds
- Critique generation: 10-15 seconds
- Full reflection loop: 60-120 seconds (2-3 iterations avg)

### **Cost Optimization:**
- Embedding cache: 90% reduction in OpenAI API calls
- Classification cache: Eliminates redundant LLM classification
- Extraction cache: Prevents re-extraction of same documents

### **Scalability:**
- Supports up to 15 files per session
- Max file size: 50MB
- Session timeout: 60 minutes
- Concurrent sessions: Limited by memory (would need Redis for production)

---

## ğŸ” Security & Best Practices

1. **API Keys**: Stored in `.env`, never in code
2. **File Upload**: Validated (PDF only), size-limited
3. **Session Isolation**: Each session has own Qdrant collection
4. **Data Cleanup**: Old sessions expire after 60 minutes
5. **CORS**: Configured for development (needs production hardening)

---

## ğŸ¯ Key Differentiators

1. **Intelligent Document Processing**: Not just text extraction - classification and structured extraction
2. **Reflection Pattern**: Iterative improvement vs one-shot generation
3. **Global Caching**: Massive cost and time savings
4. **RAG Integration**: Semantic search over documents
5. **Type-Aware Extraction**: Different extraction strategies per document type
6. **Multi-Format Support**: PDFs, DOCX, images, spreadsheets

---

## ğŸš§ Current Limitations

1. **Session Storage**: In-memory (production needs Redis/DB)
2. **Concurrency**: Limited by Python GIL and memory
3. **File Size**: 50MB limit per file
4. **LLM Context**: Large documents may exceed context window
5. **Search Tool**: Tavily integration not fully utilized

---

## ğŸ”® Future Enhancements

Potential areas for improvement:
- Persistent session storage (Redis/PostgreSQL)
- Asynchronous processing (Celery/RQ)
- Streaming responses for real-time updates
- Multi-language support
- Custom LLM fine-tuning
- Advanced diagram generation
- Collaborative editing
- Version control for plans
- Integration with project management tools (Jira, Asana)

---

## ğŸ“š Summary

This is a **sophisticated, production-grade AI system** that:

âœ… Intelligently processes multiple document types  
âœ… Uses advanced caching for speed and cost optimization  
âœ… Employs vector search for semantic understanding  
âœ… Generates high-quality project plans via iterative refinement  
âœ… Provides both API and web interface  
âœ… Follows industry best practices for Python projects  

**Architecture Highlights:**
- Clean separation of concerns
- Modular, testable components
- Comprehensive error handling
- Rich documentation
- Professional code organization

This system represents a **complete end-to-end solution** for automated project planning from document analysis to final deliverable.

---

**Last Updated**: November 4, 2025  
**Version**: 2.0.0 (Reflection Pattern)  
**Status**: Production-Ready (with noted limitations)

