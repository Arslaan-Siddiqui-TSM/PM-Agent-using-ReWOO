import os
import json
import fitz
from pathlib import Path
from src.config.llm_config import model
from rich.console import Console
from rich.panel import Panel
from rich.text import Text


console = Console()


# ============================================================================
# Helper Functions for Two-Stage Feasibility Generation
# ============================================================================

def _extract_thinking_summary(content_str: str) -> str:
    """
    Extract thinking summary from Stage 1 LLM response.
    
    Handles:
    - Delimited format with ---THINKING_SUMMARY_START--- and ---THINKING_SUMMARY_END---
    - Code fences around delimited content
    - Fallback to entire content if delimiters not found
    """
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Extracting thinking summary from Stage 1 response")
    
    # Optional: strip surrounding code fences if present
    cs_strip = content_str.strip()
    if cs_strip.startswith("```") and cs_strip.endswith("```"):
        console.print("[bold yellow]DEBUG:[/bold yellow] Stripping surrounding code fences from response")
        cs_body = cs_strip[3:]
        nl = cs_body.find("\n")
        if nl != -1:
            cs_body = cs_body[nl+1:]
        cs_body = cs_body.rstrip("`")
        content_str = cs_body.strip()

    # Try robust regex-based extraction
    import re as _re
    think_pat = _re.compile(
        r"---THINKING_SUMMARY_START---\s*(.*?)\s*(?:---THINKING_SUMMARY_END---|\Z)",
        _re.DOTALL,
    )

    m_think = think_pat.search(content_str)
    if m_think:
        thinking_summary = m_think.group(1).strip()
        console.print(f"[bold green]DEBUG:[/bold green] Extracted thinking summary via regex (len={len(thinking_summary)})")
        return thinking_summary
    
    # Fallback: use entire content
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Delimiters not found, using entire response as thinking summary")
    return content_str.strip()


def _build_stage2_prompt(thinking_summary: str, user_payload: dict, session_id: str) -> str:
    """
    Build Stage 2 prompt for feasibility report generation.
    
    Combines:
    - Stage 2 template (feasibility_report_from_thinking.txt)
    - Thinking summary from Stage 1
    - Original development_context and documents
    """
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Building Stage 2 prompt")
    
    # Load Stage 2 template
    prompt_path = Path(__file__).parent.parent.parent / "prompts" / "feasibility_report_from_thinking.txt"
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Loading Stage 2 template from: {prompt_path}")
    
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            stage2_template = f.read()
        console.print(f"[bold green]DEBUG:[/bold green] Stage 2 template loaded, length: {len(stage2_template)} characters")
    except Exception as e:
        console.print(f"[bold red]ERROR:[/bold red] Failed to load Stage 2 template: {e}")
        raise
    
    # Build user message for Stage 2
    stage2_payload = {
        "thinking_summary": thinking_summary,
        "development_context": user_payload.get("development_context", {}),
        "documents": user_payload.get("documents", user_payload.get("documents_summary", {})),
        "session_id": session_id
    }
    
    user_message_stage2 = json.dumps(stage2_payload, ensure_ascii=False, indent=2)
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Stage 2 user payload length: {len(user_message_stage2)} characters")
    
    # Combine template and payload
    full_prompt_stage2 = f"{stage2_template}\n\n---\n\nUSER PAYLOAD:\n\n{user_message_stage2}"
    
    console.print(f"[bold green]DEBUG:[/bold green] Stage 2 prompt built, total length: {len(full_prompt_stage2)} characters")
    
    return full_prompt_stage2


# DEPRECATED: This function is no longer used in the simplified pipeline.
# The new pipeline uses MD files directly instead of raw PDF extraction.
# Keeping for backward compatibility only.
def extract_text_from_pdfs(file_paths: list[str]) -> str:
    """
    DEPRECATED: Extract text from a list of PDF files.
    
    Note: This function is deprecated. The new pipeline reads from 
    markdown files generated by ParsingHandler instead of raw PDFs.
    
    Args:
        file_paths (list[str]): List of paths to the PDF files.

    Returns:
        str: The extracted text from all PDF files.
    """
    console.print(f"[bold red]WARNING:[/bold red] extract_text_from_pdfs() is deprecated. Use MD files from ParsingHandler instead.")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Starting PDF text extraction from {len(file_paths)} files")
    all_text = ""
    for file_path in file_paths:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Processing file: {file_path}")
        try:
            with fitz.open(file_path) as doc:
                console.print(f"[bold yellow]DEBUG:[/bold yellow] Document opened successfully, pages: {len(doc)}")
                page_num = 0
                for page in doc:
                    page_num += 1
                    page_text = page.get_text("text")
                    console.print(f"[bold yellow]DEBUG:[/bold yellow] Page {page_num}: extracted {len(str(page_text))} characters")
                    if isinstance(page_text, str):
                        all_text += page_text + "\n"
                    elif isinstance(page_text, list):
                        # join list elements safely
                        all_text += "\n".join(map(str, page_text)) + "\n"
                    elif isinstance(page_text, dict):
                        # fallback for dict-style returns
                        all_text += str(page_text) + "\n"
                    else:
                        # catch-all coercion
                        all_text += str(page_text) + "\n"
                console.print(f"[bold yellow]DEBUG:[/bold yellow] Finished processing {file_path}: total characters so far: {len(all_text)}")
        except Exception as e:
            console.print(f"[bold red]DEBUG ERROR:[/bold red] Failed to read {file_path}: {e}")
            all_text += f"\n[Error reading {file_path}: {e}]\n"
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Total extracted text length: {len(all_text)} characters")
    return all_text.strip()


def generate_feasibility_questions(document_text: str, development_context: dict | None = None, session_id: str = "unknown", use_v3: bool = True) -> dict:
    """Generate feasibility questions for the Tech Lead review.

    Args:
        document_text (str): The markdown text content from parsed documents.
        development_context (dict, optional): Development process information from user.
        session_id (str, optional): Session ID for the assessment.
        use_v3 (bool, optional): Use v3/v4 prompt (default: True).

    Returns:
        dict: Dictionary with keys 'thinking_summary' and 'feasibility_report' containing markdown text.
    """    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Starting feasibility question generation")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Using prompt version: {'v4' if use_v3 else 'v2'}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Input document text length: {len(document_text)} characters")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Development context provided: {development_context is not None}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Session ID: {session_id}")
    
    # Get project root directory (two levels up from this file)
    project_root = Path(__file__).parent.parent.parent
    
    # Select prompt version
    if use_v3:
        prompt_path = project_root / "prompts" / "feasibility_promptv4.txt"
    else:
        prompt_path = project_root / "prompts" / "feasibility_promptv2.txt"
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Loading prompt from: {prompt_path}")
    
    with open(prompt_path, "r", encoding="utf-8") as f:
        system_prompt = f.read()
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] System prompt loaded, length: {len(system_prompt)} characters")
    
    # Prepare text input from MD files
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Using MD file text input")
    
    # Truncate document text if too long (keep reasonable limit for token budget)
    max_doc_length = 150000 if use_v3 else 25000  # V3/V4 allows larger context
    if len(document_text) > max_doc_length:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Truncating document text to {max_doc_length} characters")
        document_text = document_text[:max_doc_length]
    
    # Prepare the user payload as per the prompt's INPUT CONTRACT
    import json
    
    # If development_context is None, provide an empty dict with "unknown" placeholder
    if development_context is None:
        development_context = {
            "note": "No development context provided by user",
            "teamSize": "unknown",
            "timeline": "unknown",
            "budget": "unknown",
            "methodology": "unknown",
            "techStack": "unknown",
            "constraints": "unknown"
        }
    
    # Build payload with MD text content
    user_payload = {
        "development_context": development_context,
        "documents_summary": {
            "session_id": session_id,
            "content": document_text,
            "source": "markdown files"
        }
    }
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Using MD text payload format")
    
    # Build the full prompt with system instructions + JSON payload
    user_message = json.dumps(user_payload, ensure_ascii=False, indent=2)
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] User payload length: {len(user_message)} characters")
    
    # Combine system prompt and user message
    full_prompt = f"{system_prompt}\n\n---\n\nUSER PAYLOAD:\n\n{user_message}"
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Full prompt length: {len(full_prompt)} characters")
    
    # Show a preview of the prompt
    console.print("\n[bold magenta]DEBUG - PROMPT PREVIEW:[/bold magenta]")
    console.print("[dim]" + "="*80 + "[/dim]")
    console.print(f"[cyan]Total prompt characters: {len(full_prompt)}[/cyan]")
    console.print(f"[cyan]User payload preview:[/cyan]")
    console.print(user_message[:500] + "..." if len(user_message) > 500 else user_message)
    console.print("[dim]" + "="*80 + "[/dim]\n")
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Starting two-stage feasibility generation...")
    
    try:
        # ============================================================
        # STAGE 1: Generate thinking summary
        # ============================================================
        console.print(f"\n[bold cyan]â•â•â• STAGE 1: GENERATING THINKING SUMMARY â•â•â•[/bold cyan]")
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Invoking LLM for Stage 1 (thinking summary)")
        
        result_stage1 = model.invoke(full_prompt)
        content_stage1 = str(getattr(result_stage1, "content", result_stage1))
        
        console.print(f"[bold green]DEBUG:[/bold green] Stage 1 LLM invocation successful")
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Stage 1 content length: {len(content_stage1)} characters")
        
        # Extract thinking summary from Stage 1
        thinking_summary = _extract_thinking_summary(content_stage1)
        console.print(f"[bold green]âœ“ STAGE 1 COMPLETE:[/bold green] Thinking summary: {len(thinking_summary)} chars")
        
        # ============================================================
        # STAGE 2: Generate feasibility report from thinking summary
        # ============================================================
        console.print(f"\n[bold cyan]â•â•â• STAGE 2: GENERATING FEASIBILITY REPORT â•â•â•[/bold cyan]")
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Building Stage 2 prompt with thinking summary")
        
        stage2_prompt = _build_stage2_prompt(thinking_summary, user_payload, session_id)
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Stage 2 prompt length: {len(stage2_prompt)} characters")
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Invoking LLM for Stage 2 (feasibility report)")
        
        result_stage2 = model.invoke(stage2_prompt)
        content_stage2 = str(getattr(result_stage2, "content", result_stage2))
        
        console.print(f"[bold green]DEBUG:[/bold green] Stage 2 LLM invocation successful")
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Stage 2 content length: {len(content_stage2)} characters")
        
        # Extract feasibility report from Stage 2 (entire response is the report)
        feasibility_report = content_stage2.strip()
        console.print(f"[bold green]âœ“ STAGE 2 COMPLETE:[/bold green] Feasibility report: {len(feasibility_report)} chars")
        
        console.print(f"\n[bold green]â•â•â• TWO-STAGE GENERATION COMPLETED SUCCESSFULLY â•â•â•[/bold green]")
        
    except Exception as e:
        console.print(f"[bold red]DEBUG ERROR:[/bold red] LLM invocation failed: {e}")
        return {
            "thinking_summary": f"Error calling LLM: {e}",
            "feasibility_report": f"Error calling LLM: {e}"
        }

    
    return {
        "thinking_summary": thinking_summary,
        "feasibility_report": feasibility_report
    }


def save_questions_to_markdown(questions_md: str, file_name: str, output_dir="outputs"):
    """Save feasibility questions to a markdown file.

    Args:
        questions_md (str): The markdown content to save.
        file_name (str): The base name for the output file (without extension).
        output_dir (str, optional): The directory to save the output file. Defaults to "outputs".

    Returns:
        str: The path to the saved markdown file.
    """    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Saving questions to markdown")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Input content length: {len(questions_md)} characters")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] File name: {file_name}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Output directory: {output_dir}")
    
    os.makedirs(output_dir, exist_ok=True)
    # Derive a sane base name from the provided file path
    base = os.path.splitext(os.path.basename(file_name))[0]
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Base filename: {base}")
    
    output_path = os.path.join(output_dir, f"{base}.md")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Full output path: {output_path}")
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(questions_md)
    
    console.print(f"[bold green]DEBUG:[/bold green] File written successfully")
    return output_path


def run_feasibility_agent(file_paths: list[str], development_context: dict | None = None, session_id: str = "standalone") -> tuple[str, str]:
    """Run the feasibility agent on multiple documents, producing two markdown files.
    
    Args:
        file_paths: List of paths to PDF files
        development_context: Optional development process information
        session_id: Session ID for tracking
        
    Returns:
        tuple: (thinking_summary_path, feasibility_report_path) - Paths to the saved markdown files
    """
    console.print(f"[bold yellow]DEBUG:[/bold yellow] === Starting Feasibility Agent ===")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Received {len(file_paths)} file paths")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Session ID: {session_id}")
    
    if not file_paths:
        console.print(Panel("No files provided for feasibility analysis.", border_style="yellow"))
        console.print(f"[bold red]DEBUG:[/bold red] Exiting early - no files provided")
        return ("", "")

    for i, fp in enumerate(file_paths, 1):
        console.print(f"[bold yellow]DEBUG:[/bold yellow] File {i}: {fp}")

    console.rule("[bold blue]ðŸ” Feasibility Agent[/bold blue]")
    console.print(f"[bold cyan]Reading {len(file_paths)} project document(s)...[/bold cyan]")

    # Combine text from all documents
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Calling extract_text_from_pdfs...")
    docs_text = extract_text_from_pdfs(file_paths)
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Text extraction complete")
    console.print(Panel(f"Extracted [bold]{len(docs_text)}[/bold] characters from all documents.", border_style="cyan"))

    # Generate assessment once for all documents combined
    console.print(Panel("Generating feasibility analysis...", border_style="magenta"))
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Calling generate_feasibility_questions...")
    result = generate_feasibility_questions(
        document_text=docs_text,
        development_context=development_context,
        session_id=session_id
    )
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Analysis generation complete")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Thinking summary length: {len(result['thinking_summary'])} characters")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Feasibility report length: {len(result['feasibility_report'])} characters")

    # Save both files
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Saving markdown files...")
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Save thinking summary
    thinking_path = save_questions_to_markdown(
        result["thinking_summary"], 
        f"thinking_summary_{session_id[:8]}_{timestamp}.md"
    )
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Thinking summary saved")
    
    # Save feasibility report
    report_path = save_questions_to_markdown(
        result["feasibility_report"], 
        f"feasibility_report_{session_id[:8]}_{timestamp}.md"
    )
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Feasibility report saved")
    
    console.print(Panel(
        f"Feasibility files saved:\n- Thinking Summary: [bold]{thinking_path}[/bold]\n- Feasibility Report: [bold]{report_path}[/bold]", 
        border_style="green"
    ))

    console.print(Panel(Text("Feasibility stage complete. Please review the reports before proceeding.",
                             justify="center"), border_style="green"))
    console.print(f"[bold yellow]DEBUG:[/bold yellow] === Feasibility Agent Complete ===")
    return (thinking_path, report_path)


def save_development_context_to_json(
    development_context: dict,
    session_id: str,
    output_dir: str = "outputs/intermediate"
) -> str:
    """Save development context data to a JSON file.
    
    Args:
        development_context (dict): Dictionary containing form data from frontend
            (methodology, teamSize, timeline, budget, techStack, constraints).
        session_id (str): Session ID associated with this context.
        output_dir (str, optional): Directory to save the JSON file. 
            Defaults to "outputs/intermediate".
    
    Returns:
        str: The path to the saved JSON file.
    """
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Saving development context to JSON")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Session ID: {session_id}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Output directory: {output_dir}")
    
    import json
    from datetime import datetime
    
    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Create filename with session ID and timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_filename = f"development_context_{session_id[:8]}_{timestamp}.json"
    json_file_path = os.path.join(output_dir, json_filename)
    
    # Prepare the JSON data structure
    json_data = {
        "session_id": session_id,
        "timestamp": datetime.now().isoformat(),
        "development_context": development_context,
    }
    
    # Save to JSON file
    with open(json_file_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    
    console.print(f"[bold green]DEBUG:[/bold green] Development context saved to: {json_file_path}")
    return json_file_path


if __name__ == "__main__":
    # Example usage - automatically reads all PDF files from the files directory
    import glob
    files_dir = "files"
    sample_files = glob.glob(os.path.join(files_dir, "*.pdf"))
    
    if not sample_files:
        console.print(f"[bold yellow]No PDF files found in {files_dir} directory[/bold yellow]")
    else:
        console.print(f"[bold cyan]Found {len(sample_files)} PDF files to process[/bold cyan]")
        questions_file = run_feasibility_agent(sample_files)
