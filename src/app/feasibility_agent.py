import os
import fitz
from pathlib import Path
from src.config.llm_config import model
from rich.console import Console
from rich.panel import Panel
from rich.text import Text


console = Console()


# DEPRECATED: This function is no longer used in the simplified pipeline.
# The new pipeline uses MD files directly instead of raw PDF extraction.
# Keeping for backward compatibility only.
def extract_text_from_pdfs(file_paths: list[str]) -> str:
    """
    DEPRECATED: Extract text from a list of PDF files.
    
    Note: This function is deprecated. The new pipeline reads from 
    markdown files generated by ParsingHandler instead of raw PDFs.
    
    Args:
        file_paths (list[str]): List of paths to the PDF files.

    Returns:
        str: The extracted text from all PDF files.
    """
    console.print(f"[bold red]WARNING:[/bold red] extract_text_from_pdfs() is deprecated. Use MD files from ParsingHandler instead.")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Starting PDF text extraction from {len(file_paths)} files")
    all_text = ""
    for file_path in file_paths:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Processing file: {file_path}")
        try:
            with fitz.open(file_path) as doc:
                console.print(f"[bold yellow]DEBUG:[/bold yellow] Document opened successfully, pages: {len(doc)}")
                page_num = 0
                for page in doc:
                    page_num += 1
                    page_text = page.get_text("text")
                    console.print(f"[bold yellow]DEBUG:[/bold yellow] Page {page_num}: extracted {len(str(page_text))} characters")
                    if isinstance(page_text, str):
                        all_text += page_text + "\n"
                    elif isinstance(page_text, list):
                        # join list elements safely
                        all_text += "\n".join(map(str, page_text)) + "\n"
                    elif isinstance(page_text, dict):
                        # fallback for dict-style returns
                        all_text += str(page_text) + "\n"
                    else:
                        # catch-all coercion
                        all_text += str(page_text) + "\n"
                console.print(f"[bold yellow]DEBUG:[/bold yellow] Finished processing {file_path}: total characters so far: {len(all_text)}")
        except Exception as e:
            console.print(f"[bold red]DEBUG ERROR:[/bold red] Failed to read {file_path}: {e}")
            all_text += f"\n[Error reading {file_path}: {e}]\n"
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Total extracted text length: {len(all_text)} characters")
    return all_text.strip()


def generate_feasibility_questions(document_text: str, development_context: dict | None = None, session_id: str = "unknown", use_v3: bool = True, md_file_paths: list[str] | None = None) -> dict:
    """Generate feasibility questions for the Tech Lead review.

    Args:
        document_text (str): The text content of the document (for v2 compatibility).
        development_context (dict, optional): Development process information from user.
        session_id (str, optional): Session ID for the assessment.
        use_v3 (bool, optional): Use v4 prompt with JSON input (default: True).
        md_file_paths (list[str], optional): List of MD file paths for v4 JSON conversion.

    Returns:
        dict: Dictionary with keys 'thinking_summary' and 'feasibility_report' containing markdown text.
    """    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Starting feasibility question generation")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Using prompt version: {'v4' if use_v3 else 'v2'}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Input document text length: {len(document_text)} characters")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Development context provided: {development_context is not None}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Session ID: {session_id}")
    
<<<<<<< Updated upstream
    # Go up two levels from src/app/ to reach project root, then into prompts/
    prompt_path = os.path.join(os.path.dirname(__file__), "..", "..", "prompts", "feasibility_promptv2.txt")
=======
    # Get project root directory (two levels up from this file)
    project_root = Path(__file__).parent.parent.parent
    
    # Select prompt version
    if use_v3:
        prompt_path = project_root / "prompts" / "feasibility_promptv4.txt"
    else:
        prompt_path = project_root / "prompts" / "feasibility_promptv2.txt"
    
>>>>>>> Stashed changes
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Loading prompt from: {prompt_path}")
    
    with open(prompt_path, "r", encoding="utf-8") as f:
        system_prompt = f.read()
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] System prompt loaded, length: {len(system_prompt)} characters")
    
    # V4-specific: Load JSON files from session directory
    documents_json = None
    if use_v3 and md_file_paths:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Looking for JSON files in session directory")
        
        # Try to load pre-converted JSON files from session directory
        try:
            # Infer JSON directory from MD file path
            md_path = Path(md_file_paths[0])
            session_dir = md_path.parent.parent  # Go up from raw/ to session_xxx/
            json_dir = session_dir / "json"
            
            if json_dir.exists():
                console.print(f"[bold green]DEBUG:[/bold green] Found JSON directory: {json_dir}")
                
                # Load all JSON files
                json_files = sorted(json_dir.glob("*.json"))
                loaded_documents = []
                
                for json_file in json_files:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        doc = json.load(f)
                        loaded_documents.append(doc)
                
                documents_json = {
                    "documents": loaded_documents,
                    "summary": {
                        "total_documents": len(loaded_documents),
                        "source": "pre_converted_json"
                    }
                }
                
                console.print(f"[bold green]DEBUG:[/bold green] Loaded {len(loaded_documents)} JSON documents")
            else:
                console.print(f"[bold yellow]DEBUG:[/bold yellow] JSON directory not found: {json_dir}")
                console.print(f"[bold yellow]DEBUG:[/bold yellow] JSON conversion may be disabled or not yet complete")
                documents_json = None
                
        except Exception as e:
            console.print(f"[bold red]WARNING:[/bold red] Failed to load JSON files: {e}")
            console.print(f"[bold yellow]DEBUG:[/bold yellow] Falling back to text-based input")
            documents_json = None
    
    # Fallback for v2 or if JSON not available
    if not documents_json:
        if use_v3:
            console.print(f"[bold yellow]DEBUG:[/bold yellow] No JSON documents available, using text-based fallback")
        # Truncate document text if too long (keep reasonable limit for token budget)
        max_doc_length = 150000 if use_v3 else 25000  # V4 allows much larger context
        if len(document_text) > max_doc_length:
            console.print(f"[bold yellow]DEBUG:[/bold yellow] Truncating document text to {max_doc_length} characters")
            document_text = document_text[:max_doc_length]
    
    # Prepare the user payload as per the prompt's INPUT CONTRACT
    import json
    
    # If development_context is None, provide an empty dict with "unknown" placeholder
    if development_context is None:
        development_context = {
            "note": "No development context provided by user",
            "teamSize": "unknown",
            "timeline": "unknown",
            "budget": "unknown",
            "methodology": "unknown",
            "techStack": "unknown",
            "constraints": "unknown"
        }
    
    # Build payload based on prompt version
    if use_v3 and documents_json:
        # V4 format: structured JSON documents
        user_payload = {
            "development_context": development_context,
            "documents": documents_json.get("documents", [])
        }
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Using v4 JSON payload with {len(user_payload['documents'])} structured documents")
    else:
        # V2 format or fallback: plain text documents_summary
        user_payload = {
            "development_context": development_context,
            "documents_summary": {
                "session_id": session_id,
                "content": document_text,
                "source": "project documents"
            }
        }
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Using v2 text payload format")
    
    # Build the full prompt with system instructions + JSON payload
    user_message = json.dumps(user_payload, ensure_ascii=False, indent=2)
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] User payload length: {len(user_message)} characters")
    
    # Combine system prompt and user message
    full_prompt = f"{system_prompt}\n\n---\n\nUSER PAYLOAD:\n\n{user_message}"
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Full prompt length: {len(full_prompt)} characters")
    
    # Show a preview of the prompt
    console.print("\n[bold magenta]DEBUG - PROMPT PREVIEW:[/bold magenta]")
    console.print("[dim]" + "="*80 + "[/dim]")
    console.print(f"[cyan]Total prompt characters: {len(full_prompt)}[/cyan]")
    console.print(f"[cyan]User payload preview:[/cyan]")
    console.print(user_message[:500] + "..." if len(user_message) > 500 else user_message)
    console.print("[dim]" + "="*80 + "[/dim]\n")
    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Invoking LLM model...")
    
    try:
        # Use v4 config if requested
        if use_v3:
            console.print(f"[bold yellow]DEBUG:[/bold yellow] Using v4 configuration for LLM")
            from src.config.feasibility_v3_config import get_v3_config
            from src.config.llm_config import UnifiedLLM
            
            v3_config = get_v3_config()
            console.print(f"[bold yellow]DEBUG:[/bold yellow] V4 Config: temperature={v3_config['temperature']}, max_tokens={v3_config['max_output_tokens']}, timeout={v3_config['timeout']}")
            
            # Create v4-optimized model instance
            v3_model = UnifiedLLM(
                provider=v3_config['preferred_provider'],
                temperature=v3_config['temperature'],
                max_output_tokens=v3_config['max_output_tokens'],
                request_timeout=v3_config['timeout']
            )
            result = v3_model.invoke(full_prompt)
        else:
            # Use default model for v2
            result = model.invoke(full_prompt)
        
        console.print(f"[bold green]DEBUG:[/bold green] LLM invocation successful")
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Result type: {type(result)}")
    except Exception as e:
        console.print(f"[bold red]DEBUG ERROR:[/bold red] LLM invocation failed: {e}")
        return {
            "thinking_summary": f"Error calling LLM: {e}",
            "feasibility_report": f"Error calling LLM: {e}"
        }

    # Normalize result to a string
    content = getattr(result, "content", result)
    content_str = str(content)
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Content type: {type(content)}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Content length: {len(content_str)} characters")
    
    # Show a preview of the LLM response
    console.print("\n[bold magenta]DEBUG - LLM RESPONSE PREVIEW:[/bold magenta]")
    console.print("[dim]" + "="*80 + "[/dim]")
    response_preview = content_str[:800] + "\n\n... [truncated] ...\n\n" + content_str[-300:] if len(content_str) > 1100 else content_str
    console.print(f"[green]{response_preview}[/green]")
    console.print("[dim]" + "="*80 + "[/dim]\n")

    # Parse the delimited response to extract both markdown documents
    thinking_summary = ""
    feasibility_report = ""

    # Optional: strip surrounding code fences if present
    cs_strip = content_str.strip()
    if cs_strip.startswith("```") and cs_strip.endswith("```"):
        console.print("[bold yellow]DEBUG:[/bold yellow] Stripping surrounding code fences from response")
        # remove only one outer layer of fences
        cs_body = cs_strip[3:]
        # drop optional language tag until first newline
        nl = cs_body.find("\n")
        if nl != -1:
            cs_body = cs_body[nl+1:]
        cs_body = cs_body.rstrip("`")
        content_str = cs_body.strip()

    # Try robust regex-based extraction (handles missing END markers)
    import re as _re
    think_pat = _re.compile(
        r"---THINKING_SUMMARY_START---\s*(.*?)\s*(?:---THINKING_SUMMARY_END---|---FEASIBILITY_REPORT_START---|\Z)",
        _re.DOTALL,
    )
    report_pat = _re.compile(
        r"---FEASIBILITY_REPORT_START---\s*(.*?)\s*(?:---FEASIBILITY_REPORT_END---|\Z)",
        _re.DOTALL,
    )

    m_think = think_pat.search(content_str)
    if m_think:
        thinking_summary = m_think.group(1).strip()
        console.print(f"[bold green]DEBUG:[/bold green] Extracted thinking summary via regex (len={len(thinking_summary)})")

    m_report = report_pat.search(content_str)
    if m_report:
        feasibility_report = m_report.group(1).strip()
        console.print(f"[bold green]DEBUG:[/bold green] Extracted feasibility report via regex (len={len(feasibility_report)})")
    
    # Fallback: try JSON parsing if delimiters not found
    if not thinking_summary or not feasibility_report:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Delimiters not found, trying JSON parsing...")
        try:
            parsed_json = json.loads(content_str)
            if isinstance(parsed_json, dict):
                thinking_summary = parsed_json.get("thinking_summary.md", thinking_summary)
                feasibility_report = parsed_json.get("feasibility_report.md", feasibility_report)
                if thinking_summary or feasibility_report:
                    console.print(f"[bold green]DEBUG:[/bold green] Successfully parsed JSON response")
        except json.JSONDecodeError:
            console.print(f"[bold yellow]DEBUG:[/bold yellow] Not valid JSON, using content as-is")
    
    # Partial fallback heuristics if only one section present
    if thinking_summary and not feasibility_report:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Feasibility report missing; leaving empty to trigger retry")
        feasibility_report = ""
    elif feasibility_report and not thinking_summary:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] Thinking summary missing; generating minimal placeholder")
        thinking_summary = "# Thinking Summary\n\n(Generated from unstructured response. Retry may improve extraction.)"

    # Final fallback: if both still empty, dump entire content as feasibility report
    if not feasibility_report and not thinking_summary:
        console.print(f"[bold yellow]DEBUG:[/bold yellow] No sections parsed; using entire response as feasibility report")
        feasibility_report = content_str
        thinking_summary = "# Thinking Summary\n\n(Generated from unstructured response)"
    
    console.print(f"[bold green]DEBUG:[/bold green] Extracted thinking summary: {len(thinking_summary)} chars")
    console.print(f"[bold green]DEBUG:[/bold green] Extracted feasibility report: {len(feasibility_report)} chars")
    
    return {
        "thinking_summary": thinking_summary,
        "feasibility_report": feasibility_report
    }


def save_questions_to_markdown(questions_md: str, file_name: str, output_dir="outputs"):
    """Save feasibility questions to a markdown file.

    Args:
        questions_md (str): The markdown content to save.
        file_name (str): The base name for the output file (without extension).
        output_dir (str, optional): The directory to save the output file. Defaults to "outputs".

    Returns:
        str: The path to the saved markdown file.
    """    
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Saving questions to markdown")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Input content length: {len(questions_md)} characters")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] File name: {file_name}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Output directory: {output_dir}")
    
    os.makedirs(output_dir, exist_ok=True)
    # Derive a sane base name from the provided file path
    base = os.path.splitext(os.path.basename(file_name))[0]
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Base filename: {base}")
    
    output_path = os.path.join(output_dir, f"{base}.md")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Full output path: {output_path}")
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(questions_md)
    
    console.print(f"[bold green]DEBUG:[/bold green] File written successfully")
    return output_path


def run_feasibility_agent(file_paths: list[str], development_context: dict | None = None, session_id: str = "standalone") -> tuple[str, str]:
    """Run the feasibility agent on multiple documents, producing two markdown files.
    
    Args:
        file_paths: List of paths to PDF files
        development_context: Optional development process information
        session_id: Session ID for tracking
        
    Returns:
        tuple: (thinking_summary_path, feasibility_report_path) - Paths to the saved markdown files
    """
    console.print(f"[bold yellow]DEBUG:[/bold yellow] === Starting Feasibility Agent ===")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Received {len(file_paths)} file paths")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Session ID: {session_id}")
    
    if not file_paths:
        console.print(Panel("No files provided for feasibility analysis.", border_style="yellow"))
        console.print(f"[bold red]DEBUG:[/bold red] Exiting early - no files provided")
        return ("", "")

    for i, fp in enumerate(file_paths, 1):
        console.print(f"[bold yellow]DEBUG:[/bold yellow] File {i}: {fp}")

    console.rule("[bold blue]ðŸ” Feasibility Agent[/bold blue]")
    console.print(f"[bold cyan]Reading {len(file_paths)} project document(s)...[/bold cyan]")

    # Combine text from all documents
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Calling extract_text_from_pdfs...")
    docs_text = extract_text_from_pdfs(file_paths)
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Text extraction complete")
    console.print(Panel(f"Extracted [bold]{len(docs_text)}[/bold] characters from all documents.", border_style="cyan"))

    # Generate assessment once for all documents combined
    console.print(Panel("Generating feasibility analysis...", border_style="magenta"))
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Calling generate_feasibility_questions...")
    result = generate_feasibility_questions(
        document_text=docs_text,
        development_context=development_context,
        session_id=session_id
    )
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Analysis generation complete")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Thinking summary length: {len(result['thinking_summary'])} characters")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Feasibility report length: {len(result['feasibility_report'])} characters")

    # Save both files
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Saving markdown files...")
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Save thinking summary
    thinking_path = save_questions_to_markdown(
        result["thinking_summary"], 
        f"thinking_summary_{session_id[:8]}_{timestamp}.md"
    )
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Thinking summary saved")
    
    # Save feasibility report
    report_path = save_questions_to_markdown(
        result["feasibility_report"], 
        f"feasibility_report_{session_id[:8]}_{timestamp}.md"
    )
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Feasibility report saved")
    
    console.print(Panel(
        f"Feasibility files saved:\n- Thinking Summary: [bold]{thinking_path}[/bold]\n- Feasibility Report: [bold]{report_path}[/bold]", 
        border_style="green"
    ))

    console.print(Panel(Text("Feasibility stage complete. Please review the reports before proceeding.",
                             justify="center"), border_style="green"))
    console.print(f"[bold yellow]DEBUG:[/bold yellow] === Feasibility Agent Complete ===")
    return (thinking_path, report_path)


def save_development_context_to_json(
    development_context: dict,
    session_id: str,
    output_dir: str = "outputs/intermediate"
) -> str:
    """Save development context data to a JSON file.
    
    Args:
        development_context (dict): Dictionary containing form data from frontend
            (methodology, teamSize, timeline, budget, techStack, constraints).
        session_id (str): Session ID associated with this context.
        output_dir (str, optional): Directory to save the JSON file. 
            Defaults to "outputs/intermediate".
    
    Returns:
        str: The path to the saved JSON file.
    """
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Saving development context to JSON")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Session ID: {session_id}")
    console.print(f"[bold yellow]DEBUG:[/bold yellow] Output directory: {output_dir}")
    
    import json
    from datetime import datetime
    
    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Create filename with session ID and timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_filename = f"development_context_{session_id[:8]}_{timestamp}.json"
    json_file_path = os.path.join(output_dir, json_filename)
    
    # Prepare the JSON data structure
    json_data = {
        "session_id": session_id,
        "timestamp": datetime.now().isoformat(),
        "development_context": development_context,
    }
    
    # Save to JSON file
    with open(json_file_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    
    console.print(f"[bold green]DEBUG:[/bold green] Development context saved to: {json_file_path}")
    return json_file_path


if __name__ == "__main__":
    # Example usage - automatically reads all PDF files from the files directory
    import glob
    files_dir = "files"
    sample_files = glob.glob(os.path.join(files_dir, "*.pdf"))
    
    if not sample_files:
        console.print(f"[bold yellow]No PDF files found in {files_dir} directory[/bold yellow]")
    else:
        console.print(f"[bold cyan]Found {len(sample_files)} PDF files to process[/bold cyan]")
        questions_file = run_feasibility_agent(sample_files)
