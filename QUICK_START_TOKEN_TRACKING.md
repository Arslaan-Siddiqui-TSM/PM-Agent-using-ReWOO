# Token Tracking Quick Start Guide

Beautiful, automatic token tracking is now built into every LLM call! ðŸŽ¨âœ¨

## Zero-Configuration Usage

Token tracking works automatically with **zero configuration needed**:

```python
from src.config.llm_config import model

# Just make your LLM calls as usual
response = model.invoke("Your prompt here")

# Beautiful token usage is automatically displayed! ðŸŽ‰
```

## What You'll See

Every LLM call now displays:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ðŸ¤– LLM Token Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Provider          OPENAI                         â”‚
â”‚ Model             gpt-4o-mini                    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚ Input Tokens      12,143                         â”‚
â”‚ Output Tokens     65,234                         â”‚
â”‚ Total Tokens      77,377                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚ Duration          8.45s                          â”‚
â”‚ Speed             7,719 tok/s                    â”‚
â”‚ Est. Cost         $0.041023                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

## Auto Session Summary

Get a summary of all calls in your session:

```python
from src.utils import enable_auto_summary

# Add this line at the start of your script
enable_auto_summary()

# Make your LLM calls...
# Session summary displays automatically when script ends!
```

Output:
```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ðŸ“Š Session Token Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Metric                     Value                â”‚
â”‚ Total Calls                5                    â”‚
â”‚ Total Input Tokens         1,234                â”‚
â”‚ Total Output Tokens        5,678                â”‚
â”‚ Total Tokens               6,912                â”‚
â”‚ Total Cost                 $0.004156            â”‚
â”‚ Session Duration           45.3s                â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

## Manual Summary

Display summary anytime:

```python
from src.utils import print_summary

# Anytime during your script
print_summary()
```

## Silent Mode

Suppress token display for specific calls:

```python
response = model.invoke("Your prompt", show_tokens=False)
```

## Test It Out

Run the test script to see it in action:

```bash
python test_token_tracking.py
```

Or try the integration example:

```bash
python example_token_tracking_integration.py
```

## Key Features

âœ… **Automatic** - Works with all existing code  
âœ… **Beautiful** - Color-coded Rich formatting  
âœ… **Accurate** - Uses provider metadata when available  
âœ… **Cost tracking** - Real-time cost estimation  
âœ… **Performance** - Shows speed and duration  
âœ… **Session stats** - Cumulative tracking across calls  

## Learn More

- Full documentation: `docs/TOKEN_TRACKING.md`
- Utilities: `src/utils/token_utils.py`
- Implementation: `src/config/llm_config.py`

## That's It!

No configuration needed. Just use your existing code and enjoy beautiful token tracking! ðŸš€

